{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79f1f573",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "import mercantile\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "from datetime import datetime, timezone\n",
    "import requests\n",
    "\n",
    "from vt2geojson.tools import vt_bytes_to_geojson\n",
    "\n",
    "import os\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import threading\n",
    "\n",
    "\n",
    "import gzip\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e13fb89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "117696ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tiles_from_json(bundesland_id, input_folder=\"output/tile_cache\"):\n",
    "    path = os.path.join(input_folder, f\"{bundesland_id}_tiles.json\")\n",
    "    with open(path, \"r\") as f:\n",
    "        tile_list = json.load(f)\n",
    "    return [mercantile.Tile(**t) for t in tile_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5097a00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fe9793",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdd931ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def export_geodata(gdfs, output_folder=\"output\", base_name=\"mapillary_traffic-signs\", region=\"ger\", save_parquet=True, save_geojson_gz=True):\n",
    "    \"\"\"\n",
    "    Export one or more GeoDataFrames into output files (.parquet and/or .geojson.gz).\n",
    "    \n",
    "    Args:\n",
    "        gdfs (list or GeoDataFrame): List of GeoDataFrames or a single GeoDataFrame.\n",
    "        output_folder (str): Output directory (created if it doesn't exist).\n",
    "        base_name (str): Base filename prefix.\n",
    "        region (str): Region tag for filename.\n",
    "        save_parquet (bool): Save .parquet file.\n",
    "        save_geojson_gz (bool): Save .geojson.gz file.\n",
    "    \"\"\"\n",
    "    if gdfs is None or (isinstance(gdfs, (gpd.GeoDataFrame, pd.DataFrame)) and gdfs.empty):\n",
    "        print(\"No data to export.\")\n",
    "        return\n",
    "\n",
    "    # Concatenate if needed\n",
    "    if isinstance(gdfs, list):\n",
    "        gdf = gpd.GeoDataFrame(pd.concat(gdfs, ignore_index=True))\n",
    "    else:\n",
    "        gdf = gdfs\n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "    if save_parquet:\n",
    "        parquet_path = os.path.join(output_folder, f\"{base_name}_{region}_{current_date}.parquet\")\n",
    "        gdf.to_parquet(parquet_path, index=False)\n",
    "        print(f\"‚úî Parquet saved to: {parquet_path}\")\n",
    "\n",
    "    if save_geojson_gz:\n",
    "        geojson_path = os.path.join(output_folder, f\"{base_name}_{region}_{current_date}.geojson\")\n",
    "        gz_path = geojson_path + \".gz\"\n",
    "\n",
    "        gdf.to_file(geojson_path, driver=\"GeoJSON\")\n",
    "\n",
    "        with open(geojson_path, 'rb') as f_in, gzip.open(gz_path, 'wb') as f_out:\n",
    "            f_out.writelines(f_in)\n",
    "\n",
    "        os.remove(geojson_path)\n",
    "        print(f\"‚úî Gzipped GeoJSON saved to: {gz_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8249bb61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "817bc8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_bundesland(bundesland_id, region_name=None, input_folder=\"output/tile_cache\", output_folder=\"output\", max_workers=6, limit_tiles=None):\n",
    "    print(f\"‚ñ∂Ô∏è Starte Verarbeitung f√ºr {bundesland_id}...\")\n",
    "\n",
    "    tiles = load_tiles_from_json(bundesland_id, input_folder=input_folder)\n",
    "    if limit_tiles:\n",
    "        tiles = tiles[:limit_tiles]\n",
    "\n",
    "    def process_tile(tile):\n",
    "\n",
    "        # Load your access token\n",
    "        with open(\"config.json\") as f:\n",
    "            ACCESS_TOKEN = json.load(f)[\"ACCESS_TOKEN\"]\n",
    "\n",
    "        # Use existing variables\n",
    "        tile_layer = 'traffic_sign'  # already defined\n",
    "        tile_coverage = \"mly_map_feature_traffic_sign\"\n",
    "        \n",
    "        url = f\"https://tiles.mapillary.com/maps/vtp/{tile_coverage}/2/{tile.z}/{tile.x}/{tile.y}?access_token={ACCESS_TOKEN}\"\n",
    "        response = requests.get(url)\n",
    "        if response.status_code != 200:\n",
    "            return None\n",
    "        try:\n",
    "            geojson = vt_bytes_to_geojson(response.content, tile.x, tile.y, tile.z, layer=tile_layer)\n",
    "            features = geojson.get(\"features\", [])\n",
    "            if not features:\n",
    "                return None\n",
    "            gdf_tile = gpd.GeoDataFrame.from_features(features, crs=\"EPSG:4326\")\n",
    "            gdf_tile['first_seen_at'] = gdf_tile['first_seen_at'].apply(lambda x: datetime.fromtimestamp(x / 1000, tz=timezone.utc)).dt.strftime('%Y-%m-%d')\n",
    "            gdf_tile['last_seen_at'] = gdf_tile['last_seen_at'].apply(lambda x: datetime.fromtimestamp(x / 1000, tz=timezone.utc)).dt.strftime('%Y-%m-%d')\n",
    "            gdf_tile['tile_x'] = tile.x\n",
    "            gdf_tile['tile_y'] = tile.y\n",
    "            return gdf_tile\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Fehler bei Tile {tile.x}/{tile.y}: {e}\")\n",
    "            return None\n",
    "\n",
    "    gdf_all = []\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(process_tile, tile): tile for tile in tiles}\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=f\"üß© {bundesland_id}\"): #, leave=False\n",
    "            result = future.result()\n",
    "            if result is not None:\n",
    "                gdf_all.append(result)\n",
    "\n",
    "    if gdf_all:\n",
    "        gdf_all = gpd.GeoDataFrame(pd.concat(gdf_all, ignore_index=True))\n",
    "        export_geodata(\n",
    "            gdfs=gdf_all,\n",
    "            output_folder=output_folder,\n",
    "            region=bundesland_id,\n",
    "            save_parquet=True,\n",
    "            save_geojson_gz=True\n",
    "        )\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Keine Daten f√ºr {bundesland_id}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13431775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eccb110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñ∂Ô∏è Starte Verarbeitung f√ºr DE-BW...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üß© DE-BW: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13618/13618 [15:14<00:00, 14.89it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úî Parquet saved to: output/mapillary_traffic-signs_DE-BW_2025-08-04.parquet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Alle Bundesl√§nder im tile_cache verarbeiten\n",
    "\n",
    "bland = gpd.read_file(\"https://raw.githubusercontent.com/isellsoap/deutschlandGeoJSON/main/2_bundeslaender/1_sehr_hoch.geo.json\")\n",
    "\n",
    "#for _, row in bland[:1].iterrows():\n",
    "for _, row in bland.iterrows():\n",
    "\n",
    "    b_id = row[\"id\"]\n",
    "    name = row[\"name\"]\n",
    "\n",
    "    # Nur verarbeiten, wenn eine JSON-Datei existiert\n",
    "    tile_json_path = os.path.join(\"output/tile_cache\", f\"{b_id}_tiles.json\")\n",
    "    if not os.path.exists(tile_json_path):\n",
    "        print(f\"‚è© √úberspringe {b_id}, keine Tiles gefunden.\")\n",
    "        continue\n",
    "\n",
    "    process_bundesland(b_id, region_name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce2b771",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
